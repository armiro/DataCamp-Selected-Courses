{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction_to_Databases_in_Python.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "kqN7olf9IyIx"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armiro/DataCamp-Selected-Courses/blob/master/Introduction%20to%20Databases%20in%20Python/Introduction_to_Databases_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqN7olf9IyIx",
        "colab_type": "text"
      },
      "source": [
        "# Basics of Relational Databases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nli1X9nJI_By",
        "colab_type": "text"
      },
      "source": [
        "## Engines and Connection Strings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0uFizJMJCpT",
        "colab_type": "text"
      },
      "source": [
        "Alright, it's time to create your first engine! An engine is just a common interface to a database, and the information it requires to connect to one is contained in a connection string, such as `sqlite:///census_nyc.sqlite`. Here, `sqlite` is the database driver, while `census_nyc.sqlite` is a SQLite file contained in the local directory.\n",
        "\n",
        "You can learn a lot more about connection strings in the [SQLAlchemy documentation](http://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGtOsntXJgla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import create_engine\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Create an engine that connects to the census.sqlite file: engine\n",
        "engine = create_engine(\"sqlite:///census.sqlite\")\n",
        "connection = engine.connect()\n",
        "\n",
        "# Print table names\n",
        "print(engine.table_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXQt1AKOJ9Kl",
        "colab_type": "text"
      },
      "source": [
        "## Autoloading Tables from a Database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KYit-vCKuY-",
        "colab_type": "text"
      },
      "source": [
        "SQLAlchemy can be used to automatically load tables from a database using something called reflection. Reflection is the process of reading the database and building the metadata based on that information. It's the opposite of creating a Table by hand and is very useful for working with existing databases. \n",
        "\n",
        "To perform reflection, you need to import the `Table` object from the SQLAlchemy package. Then, you use this `Table` object to read your table from the engine and autoload the columns. Using the `Table` object in this manner is a lot like passing arguments to a function. For example, to autoload the columns with the engine, you have to specify the keyword arguments `autoload=True` and `autoload_with=engine` to `Table()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbOOq2GNLLvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Table\n",
        "from sqlalchemy import Table, MetaData\n",
        "\n",
        "# Reflect census table from the engine: census\n",
        "metadata = MetaData()\n",
        "census = Table(\"census\", metadata, autoload=True, autoload_with=engine)\n",
        "\n",
        "# Print census table metadata\n",
        "print(repr(census))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR1cISwoL5Nk",
        "colab_type": "text"
      },
      "source": [
        "## Viewing Table Details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlfyhX0ANGAT",
        "colab_type": "text"
      },
      "source": [
        "Great job reflecting the `census` table! Now you can begin to learn more about the columns and structure of your table. It is important to get an understanding of your database by examining the column names. This can be done by using the `.columns` attribute and accessing the `.keys()` method. For example, `census.columns.keys()` would return a list of column names of the census table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZivtoQ_NOuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the column names\n",
        "print(census.columns.keys())\n",
        "\n",
        "# Print full table metadata\n",
        "print(repr(metadata.tables['census']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWiTT8rRNZF6",
        "colab_type": "text"
      },
      "source": [
        "## Selecting data from a Table: raw SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR8As4T2OD7W",
        "colab_type": "text"
      },
      "source": [
        "Using what we just learned about SQL and applying the `.execute()` method on our connection, we can leverage a raw SQL query to query all the records in our `census` table. The object returned by the `.execute()` method is a **ResultProxy**. On this ResultProxy, we can then use the `.fetchall()` method to get our results - that is, the **ResultSet**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VNrKxkMRpAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build select statement for census table: stmt\n",
        "stmt = 'SELECT * FROM census'\n",
        "\n",
        "# Execute the statement and fetch the results: results\n",
        "results = connection.execute(stmt).fetchall()\n",
        "\n",
        "# Print results\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBgG4u3dR7z2",
        "colab_type": "text"
      },
      "source": [
        "## Selecting data from a Table with SQLAlchemy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2UsNskQTosx",
        "colab_type": "text"
      },
      "source": [
        "Excellent work so far! It's now time to build your first select statement using SQLAlchemy. SQLAlchemy provides a nice \"Pythonic\" way of interacting with databases. So rather than dealing with the differences between specific dialects of traditional SQL such as MySQL or PostgreSQL, you can leverage the Pythonic framework of SQLAlchemy to streamline your workflow and more efficiently query your data. For this reason, it is worth learning even if you may already be familiar with traditional SQL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfoHihELTtzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import select\n",
        "from sqlalchemy import select\n",
        "\n",
        "# Build select statement for census table: stmt\n",
        "stmt = select([census])\n",
        "\n",
        "# Print the emitted statement to see the SQL emitted\n",
        "print(stmt)\n",
        "\n",
        "# Execute the statement and print the results\n",
        "print(connection.execute(stmt).fetchall())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXRx8kS6TzjV",
        "colab_type": "text"
      },
      "source": [
        "## Handling a ResultSet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg7cptCTV_WH",
        "colab_type": "text"
      },
      "source": [
        "Recall the differences between a ResultProxy and a ResultSet:\n",
        "\n",
        "*   ResultProxy: The object returned by the `.execute()` method. It can be used in a variety of ways to get the data returned by the query.\n",
        "*   ResultSet: The actual data asked for in the query when using a fetch method such as `.fetchall()` on a ResultProxy.\n",
        "\n",
        "This separation between the ResultSet and ResultProxy allows us to fetch as much or as little data as we desire.\n",
        "\n",
        "Once we have a ResultSet, we can use Python to access all the data within it by column name and by list style indexes. For example, you can get the first row of the results by using `results[0]`. With that first row then assigned to a variable first_row, you can get data from the first column by either using `first_row[0]` or by column name such as `first_row['column_name']`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg7gDi9CWkXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the first row of the results by using an index: first_row\n",
        "first_row = results[0]\n",
        "\n",
        "# Print the first row of the results\n",
        "print(first_row)\n",
        "\n",
        "# Print the first column of the first row by using an index\n",
        "print(first_row[0])\n",
        "\n",
        "# Print the 'state' column of the first row by using its name\n",
        "print(first_row['state'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZId6OnGWuWO",
        "colab_type": "text"
      },
      "source": [
        "# Applying Filtering, Ordering and Grouping to Queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb93_JLyWyjK",
        "colab_type": "text"
      },
      "source": [
        "## Connecting to a PostgreSQL Database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePTpLl7hyDTS",
        "colab_type": "text"
      },
      "source": [
        "In these exercises, you will be working with real databases hosted on the cloud via Amazon Web Services (AWS)!\n",
        "\n",
        "Let's begin by connecting to a PostgreSQL database. When connecting to a PostgreSQL database, many prefer to use the psycopg2 database driver as it supports practically all of PostgreSQL's features efficiently and is the standard dialect for PostgreSQL in SQLAlchemy.\n",
        "\n",
        "You might recall from Chapter 1 that we use the `create_engine()` function and a connection string to connect to a database.\n",
        "\n",
        "There are three components to the connection string in this exercise: the dialect and driver (`'postgresql+psycopg2://'`), followed by the username and password (`'student:datacamp'`), followed by the host and port (`'@postgresql.csrrinzqubik.us-east-1.rds.amazonaws.com:5432/'`), and finally, the database name (`'census'`). You will have to pass this string as an argument to `create_engine()` in order to connect to the database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQUWE3zbyZnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import create_engine function\n",
        "from sqlalchemy import create_engine, select\n",
        "\n",
        "# Create an engine to the census database\n",
        "engine = create_engine('postgresql+psycopg2://student:datacamp@postgresql.csrrinzqubik.us-east-1.rds.amazonaws.com:5432/census')\n",
        "\n",
        "# Use the .table_names() method on the engine to print the table names\n",
        "print(engine.table_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ql-lI-cym_C",
        "colab_type": "text"
      },
      "source": [
        "## Filter data selected from a Table - Simple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjZ6yNgJynyv",
        "colab_type": "text"
      },
      "source": [
        "Having connected to the database, it's now time to practice filtering your queries!\n",
        "\n",
        "As mentioned in the video, a `where()` clause is used to filter the data that a statement returns. For example, to select all the records from the `census` table where the sex is Female (or `'F'`) we would do the following:\n",
        "\n",
        "`select([census]).where(census.columns.sex == 'F')`\n",
        "\n",
        "In addition to `==` we can use basically any python comparison operator (such as `<=`, `!=`, etc) in the `where()` clause."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dz-LKUs9tANc",
        "colab": {}
      },
      "source": [
        "# (as we do not have permission to access cloud-hosted postgresql,\n",
        "# we have to connect through the locally uploaded sqlite database!)\n",
        "from sqlalchemy import Table, MetaData\n",
        "engine = create_engine(\"sqlite:///census.sqlite\")\n",
        "connection = engine.connect()\n",
        "metadata = MetaData()\n",
        "census = Table(\"census\", metadata, autoload=True, autoload_with=engine)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUlqExnCy6pp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a select query: stmt\n",
        "stmt = select([census])\n",
        "\n",
        "# Add a where clause to filter the results to only those for New York\n",
        "stmt = stmt.where(census.columns.state == 'New York')\n",
        "\n",
        "# Execute the query to retrieve all the data returned: results\n",
        "results = connection.execute(stmt).fetchall()\n",
        "\n",
        "# Loop over the results and print the age, sex, and pop2008\n",
        "for result in results:\n",
        "    print(result.age, result.sex, result.pop2008)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hccd5a06E9nm",
        "colab_type": "text"
      },
      "source": [
        "## Filter data selected from a Table - Expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biw77Us2E_9v",
        "colab_type": "text"
      },
      "source": [
        "In addition to standard Python comparators, we can also use methods such as `in_()` to create more powerful `where()` clauses. You can see a full list of expressions in the [SQLAlchemy Documentation](http://docs.sqlalchemy.org/en/latest/core/sqlelement.html#module-sqlalchemy.sql.expression)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4Bl9YJ0thIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (we've already created a list of some of the most densely populated states)\n",
        "states = ['New York', 'California', 'Texas']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN2L8kB7FOAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a query for the census table: stmt\n",
        "stmt = select([census])\n",
        "\n",
        "# Append a where clause to match all the states in_ the list states\n",
        "stmt = stmt.where(census.columns.state.in_(states))\n",
        "\n",
        "# Loop over the ResultProxy and print the state and its population in 2000\n",
        "for result in connection.execute(stmt):\n",
        "    print(result.state, result.pop2000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSB_vU1FF9wR",
        "colab_type": "text"
      },
      "source": [
        "## Filter data selected from a Table - Advanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "500bIZ_RF-k9",
        "colab_type": "text"
      },
      "source": [
        "You're really getting the hang of this! SQLAlchemy also allows users to use conjunctions such as `and_()`, `or_()`, and `not_()` to build more complex filtering. For example, we can get a set of records for people in New York who are 21 or 37 years old with the following code:\n",
        "\n",
        "```\n",
        "select([census]).where(\n",
        "  and_(census.columns.state == 'New York',\n",
        "       or_(census.columns.age == 21,\n",
        "          census.columns.age == 37\n",
        "         )\n",
        "      )\n",
        "  )\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV8PmqWFGP2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import and_\n",
        "from sqlalchemy import and_\n",
        "\n",
        "# Build a query for the census table: stmt\n",
        "stmt = select([census])\n",
        "\n",
        "# Append a where clause to select only non-male records from California using and_\n",
        "stmt = stmt.where(\n",
        "    # The state of California with a non-male sex\n",
        "    and_(census.columns.state == 'California',\n",
        "         census.columns.sex != 'M'\n",
        "        )\n",
        ")\n",
        "\n",
        "# Loop over the ResultProxy printing the age and sex\n",
        "for result in connection.execute(stmt):\n",
        "    print(result.age, result.sex)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDPv19a7GSjI",
        "colab_type": "text"
      },
      "source": [
        "## Ordering by a Single Column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBjVCV5RGWkz",
        "colab_type": "text"
      },
      "source": [
        "To sort the result output by a field, we use the `.order_by()` method. By default, the `.order_by()` method sorts from lowest to highest on the supplied column. You just have to pass in the name of the column you want sorted to `.order_by()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDyFPurpGeHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a query to select the state column: stmt\n",
        "stmt = select([census.columns.state])\n",
        "\n",
        "# Order stmt by the state column\n",
        "stmt = stmt.order_by(census.columns.state)\n",
        "\n",
        "# Execute the query and store the results: results\n",
        "results = connection.execute(stmt).fetchall()\n",
        "\n",
        "# Print the first 10 results\n",
        "print(results[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6WVWxoYGf-M",
        "colab_type": "text"
      },
      "source": [
        "## Ordering in Descending Order by a Single Column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYOzPV04GkVk",
        "colab_type": "text"
      },
      "source": [
        "You can also use `.order_by()` to sort from highest to lowest by wrapping a column in the `desc()` function. Although you haven't seen this function in action, it generalizes what you have already learned.\n",
        "\n",
        "Pass `desc()` (for \"descending\") inside an `.order_by()` with the name of the column you want to sort by. For instance, `stmt.order_by(desc(table.columns.column_name))` sorts `column_name` in descending order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPYdWm7gHa0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import desc\n",
        "from sqlalchemy import desc\n",
        "\n",
        "# Build a query to select the state column: stmt\n",
        "stmt = select([census.columns.state])\n",
        "\n",
        "# Order stmt by state in descending order: rev_stmt\n",
        "rev_stmt = stmt.order_by(desc(census.columns.state))\n",
        "\n",
        "# Execute the query and store the results: rev_results\n",
        "rev_results = connection.execute(rev_stmt).fetchall()\n",
        "\n",
        "# Print the first 10 rev_results\n",
        "print(rev_results[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkUcXznEHckf",
        "colab_type": "text"
      },
      "source": [
        "## Ordering by Multiple Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQHllZTMHeom",
        "colab_type": "text"
      },
      "source": [
        "We can pass multiple arguments to the `.order_by()` method to order by multiple columns. In fact, we can also sort in ascending or descending order for each individual column. Each column in the `.order_by()` method is fully sorted from left to right. This means that the first column is completely sorted, and then within each matching group of values in the first column, it's sorted by the next column in the `.order_by()` method. This process is repeated until all the columns in the `.order_by()` are sorted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlnTg5tDHl1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a query to select state and age: stmt\n",
        "stmt = select([census.columns.state, census.columns.age])\n",
        "\n",
        "# Append order by to ascend by state and descend by age\n",
        "stmt = stmt.order_by(census.columns.state, desc(census.columns.age))\n",
        "\n",
        "# Execute the statement and store all the records: results\n",
        "results = connection.execute(stmt).fetchall()\n",
        "\n",
        "# Print the first 20 results\n",
        "print(results[:20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7OT0zcKHpiY",
        "colab_type": "text"
      },
      "source": [
        "## Counting Distinct Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKSNGzELHuIu",
        "colab_type": "text"
      },
      "source": [
        "As mentioned in the video, SQLAlchemy's `func` module provides access to built-in SQL functions that can make operations like counting and summing faster and more efficient.\n",
        "\n",
        "In the video, Jason used `func.sum()` to get a **sum** of the `pop2008` column of `census` as shown below:\n",
        "\n",
        "\n",
        "> `select([func.sum(census.columns.pop2008)])`\n",
        "\n",
        "\n",
        "If instead you want to **count** the number of values in `pop2008`, you could use `func.count()` like this:\n",
        "\n",
        "> `select([func.count(census.columns.pop2008)])`\n",
        "\n",
        "Furthermore, if you only want to count the **distinct** values of `pop2008`, you can use the `.distinct()` method:\n",
        "\n",
        "> `select([func.count(census.columns.pop2008.distinct())])`\n",
        "\n",
        "In this exercise, you will practice using `func.count()` and `.distinct()` to get a count of the distinct number of states in census.\n",
        "\n",
        "So far, you've seen `.fetchall()` and `.first()` used on a ResultProxy to get the results. The ResultProxy also has a method called `.scalar()` for getting just the value of a query that returns only one row and column.\n",
        "\n",
        "This can be very useful when you are querying for just a count or sum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQBfmKa3toLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (at first we have to import func)\n",
        "from sqlalchemy import func"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3yNAMa-IULT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a query to count the distinct states values: stmt\n",
        "stmt = select([func.count(census.columns.state.distinct())])\n",
        "\n",
        "# Execute the query and store the scalar result: distinct_state_count\n",
        "distinct_state_count = connection.execute(stmt).scalar()\n",
        "\n",
        "# Print the distinct_state_count\n",
        "print(distinct_state_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaCPwFEmIxA0",
        "colab_type": "text"
      },
      "source": [
        "## Count of Records by State"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWT8i3qKIxz7",
        "colab_type": "text"
      },
      "source": [
        "Often, we want to get a count for each record with a particular value in another column. The `.group_by()` method helps answer this type of query. You can pass a column to the `.group_by()` method and use in an aggregate function like `sum()` or `count()`. Much like the `.order_by()` method, `.group_by()` can take multiple columns as arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQGu96AfI667",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a query to select the state and count of ages by state: stmt\n",
        "stmt = select([census.columns.state, func.count(census.columns.age)])\n",
        "\n",
        "# Group stmt by state\n",
        "stmt = stmt.group_by(census.columns.state)\n",
        "\n",
        "# Execute the statement and store all the records: results\n",
        "results = connection.execute(stmt).fetchall()\n",
        "\n",
        "# Print results\n",
        "print(results)\n",
        "\n",
        "# Print the keys/column names of the results returned\n",
        "print(results[0].keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vChrX6AcJBjH",
        "colab_type": "text"
      },
      "source": [
        "## Determining the Population Sum by State"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgutF0weJCRL",
        "colab_type": "text"
      },
      "source": [
        "To avoid confusion with query result column names like `count_1`, we can use the `.label()` method to provide a name for the resulting column. This gets appended to the function method we are using, and its argument is the name we want to use.\n",
        "\n",
        "We can pair `func.sum()` with `.group_by()` to get a sum of the population by `State` and use the `label()` method to name the output.\n",
        "\n",
        "We can also create the `func.sum()` expression before using it in the select statement. We do it the same way we would inside the select statement and store it in a variable. Then we use that variable in the select statement where the `func.sum()` would normally be."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtmC3luGJQOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build an expression to calculate the sum of pop2008 labeled as population\n",
        "pop2008_sum = func.sum(census.columns.pop2008).label('population')\n",
        "\n",
        "# Build a query to select the state and sum of pop2008: stmt\n",
        "stmt = select([census.columns.state, pop2008_sum])\n",
        "\n",
        "# Group stmt by state\n",
        "stmt = stmt.group_by(census.columns.state)\n",
        "\n",
        "# Execute the statement and store all the records: results\n",
        "results = connection.execute(stmt).fetchall()\n",
        "\n",
        "# Print results\n",
        "print(sorted(results))\n",
        "\n",
        "# Print the keys/column names of the results returned\n",
        "print(results[0].keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCw5NtjjJWCf",
        "colab_type": "text"
      },
      "source": [
        "## SQLAlchemy ResultsProxy and Pandas Dataframes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aulmk46fJW2E",
        "colab_type": "text"
      },
      "source": [
        "We can feed a ResultProxy directly into a pandas DataFrame, which is the workhorse of many Data Scientists in PythonLand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feNJ6vSHJanY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame from the results: df\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Set column names\n",
        "df.columns = results[0].keys()\n",
        "\n",
        "# Print the Dataframe\n",
        "print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmsxJiyVJe-0",
        "colab_type": "text"
      },
      "source": [
        "## From SQLAlchemy results to a Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWgZMFPVJftb",
        "colab_type": "text"
      },
      "source": [
        "We can also take advantage of `pandas` and `Matplotlib` to build figures of our data. Remember that data visualization is essential for both exploratory data analysis and communication of your data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdD6cgWHJjBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import pyplot as plt from matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a DataFrame from the results: df\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Set Column names\n",
        "df.columns = results[0].keys()\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n",
        "\n",
        "# Plot the DataFrame\n",
        "df.plot.bar()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjaT3SkmKH5U",
        "colab_type": "text"
      },
      "source": [
        "# Advanced SQLAlchemy Queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c5Z1bl8KMmR",
        "colab_type": "text"
      },
      "source": [
        "## Connecting to a MySQL Database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRhCz16CZwL7",
        "colab_type": "text"
      },
      "source": [
        "Before you jump into the calculation exercises, let's begin by connecting to our database. Recall that in the last chapter you connected to a PostgreSQL database. Now, you'll connect to a MySQL database, for which many prefer to use the `pymysql` database driver, which, like `psycopg2` for PostgreSQL, you have to install prior to use.\n",
        "\n",
        "This connection string is going to start with `'mysql+pymysql://'`, indicating which dialect and driver you're using to establish the connection. The dialect block is followed by the `'username:password'` combo. Next, you specify the host and port with the following `'@host:port/'`. Finally, you wrap up the connection string with the `'database_name'`.\n",
        "\n",
        "Now you'll practice connecting to a MySQL database: it will be the same `census` database that you have already been working with. One of the great things about SQLAlchemy is that, after connecting, it abstracts over the type of database it has connected to and you can write the same SQLAlchemy code, regardless!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUBfGoN4VY98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (we have to install pymysql separately; \n",
        "# run this command just for the first time)\n",
        "!pip install pymysql"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW7EzJ6kVEui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import create_engine function\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Create an engine to the census database\n",
        "engine = create_engine('mysql+pymysql://student:datacamp@courses.csrrinzqubik.us-east-1.rds.amazonaws.com:3306/census')\n",
        "\n",
        "# Print the table names\n",
        "print(engine.table_names())\n",
        "\n",
        "# (after that, we have to reflect the census table)\n",
        "from sqlalchemy import MetaData, Table\n",
        "connection = engine.connect()\n",
        "metadata = MetaData()\n",
        "census = Table('census', metadata, autoload=True, autoload_with=engine)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCE79c9LaYKM",
        "colab_type": "text"
      },
      "source": [
        "## Calculating a Difference between Two Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMtO5zUHaZC8",
        "colab_type": "text"
      },
      "source": [
        "Often, you'll need to perform math operations as part of a query, such as if you wanted to calculate the change in population from 2000 to 2008. For math operations on numbers, the operators in SQLAlchemy work the same way as they do in Python.\n",
        "\n",
        "You can use these operators to perform addition (`+`), subtraction (`-`), multiplication (`*`), division (`/`), and modulus (`%`) operations. Note: They behave differently when used with non-numeric column types.\n",
        "\n",
        "Let's now find the top 5 states by population growth between 2000 and 2008."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQDqOSj-sga3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (import related modules from the sqlalchemy)\n",
        "from sqlalchemy import select, desc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiuM8cg9akHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build query to return state names by population difference from 2008 to 2000: stmt\n",
        "stmt = select([census.columns.state, (census.columns.pop2008-census.columns.pop2000).label('pop_change')])\n",
        "\n",
        "# Append group by for the state: stmt\n",
        "stmt = stmt.group_by(census.columns.state)\n",
        "\n",
        "# Append order by for pop_change descendingly: stmt\n",
        "stmt = stmt.order_by(desc('pop_change'))\n",
        "\n",
        "# Return only 5 results: stmt\n",
        "stmt = stmt.limit(5)\n",
        "\n",
        "# Use connection to execute the statement and fetch all results\n",
        "results = connection.execute(stmt).fetchall()\n",
        "\n",
        "# Print the state and population change for each record\n",
        "for result in results:\n",
        "    print('{}:{}'.format(result.state, result.pop_change))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XLJkR5Ocme3",
        "colab_type": "text"
      },
      "source": [
        "## Determining the Overall Percentage of Females"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1mI1yCNcpTe",
        "colab_type": "text"
      },
      "source": [
        "It's possible to combine functions and operators in a single select statement as well. These combinations can be exceptionally handy when we want to calculate percentages or averages, and we can also use the `case()` expression to operate on data that meets specific criteria while not affecting the query as a whole. The `case()` expression accepts a list of conditions to match and the column to return if the condition matches, followed by an `else_` if none of the conditions match. We can wrap this entire expression in any function or math operation we like.\n",
        "\n",
        "Often when performing integer division, we want to get a float back. While some databases will do this automatically, you can use the `cast()` function to convert an expression to a particular type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MryazuXyc1VC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import case, cast and Float from sqlalchemy\n",
        "from sqlalchemy import case, cast, Float, func\n",
        "\n",
        "# Build an expression to calculate female population in 2000\n",
        "female_pop2000 = func.sum(\n",
        "    case([\n",
        "        (census.columns.sex == 'F', census.columns.pop2000)\n",
        "    ], else_=0))\n",
        "\n",
        "# Cast an expression to calculate total population in 2000 to Float\n",
        "total_pop2000 = cast(func.sum(census.columns.pop2000), Float)\n",
        "\n",
        "# Build a query to calculate the percentage of females in 2000: stmt\n",
        "stmt = select([female_pop2000 / total_pop2000 * 100])\n",
        "\n",
        "# Execute the query and store the scalar result: percent_female\n",
        "percent_female = connection.execute(stmt).scalar()\n",
        "\n",
        "# Print the percentage\n",
        "print(percent_female)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2PuDE5QdEtE",
        "colab_type": "text"
      },
      "source": [
        "## Automatic Joins with an Established Relationship"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dUrnZvZdHIv",
        "colab_type": "text"
      },
      "source": [
        "If you have two tables that already have an established relationship, you can automatically use that relationship by just adding the columns we want from each table to the select statement. Recall that Jason constructed the following query:\n",
        "\n",
        "`stmt = select([census.columns.pop2008, state_fact.columns.abbreviation])`\n",
        "\n",
        "in order to join the `census` and `state_fact` tables and select the `pop2008` column from the first and the `abbreviation` column from the second. In this case, the `census` and `state_fact` tables had a pre-defined relationship: the `state` column of the former corresponded to the `name` column of the latter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi5klcWasXqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (first, we have to reflect the state_fact table)\n",
        "mtd = MetaData()\n",
        "state_fact = Table('state_fact', mtd, autoload=True, autoload_with=engine)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_tghnpndbAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a statement to join census and state_fact tables: stmt\n",
        "stmt = select([census.columns.pop2000, state_fact.columns.abbreviation])\n",
        "\n",
        "# Execute the statement and get the first result: result\n",
        "result = connection.execute(stmt).first()\n",
        "\n",
        "# Loop over the keys in the result object and print the key and value\n",
        "for key in result.keys():\n",
        "    print(key, getattr(result, key))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMhc0XnyeJWQ",
        "colab_type": "text"
      },
      "source": [
        "## Joins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylFqtFyXeMbW",
        "colab_type": "text"
      },
      "source": [
        "If you aren't selecting columns from both tables or the two tables don't have a defined relationship, you can still use the `.join()` method on a table to join it with another table and get extra data related to our query. The `join()` takes the table object you want to join in as the first argument and a condition that indicates how the tables are related to the second argument. Finally, you use the `.select_from()` method on the select statement to wrap the join clause. For example, in the video, Jason executed the following code to join the `census` table to the `state_fact` table such that the `state` column of the `census` table corresponded to the `name` column of the `state_fact` table.\n",
        "\n",
        "```\n",
        "stmt = stmt.select_from(\n",
        "    census.join(\n",
        "        state_fact, census.columns.state == \n",
        "        state_fact.columns.name)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SovozFK-elX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a statement to select the census and state_fact tables: stmt\n",
        "stmt = select([census, state_fact])\n",
        "\n",
        "# Add a select_from clause that wraps a join for the census and state_fact\n",
        "# tables where the census state column and state_fact name column match\n",
        "stmt = stmt.select_from(\n",
        "    census.join(state_fact, census.columns.state == state_fact.columns.name))\n",
        "\n",
        "# Execute the statement and get the first result: result\n",
        "result = connection.execute(stmt).first()\n",
        "\n",
        "# Loop over the keys in the result object and print the key and value\n",
        "for key in result.keys():\n",
        "    print(key, getattr(result, key))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaqwcktperp1",
        "colab_type": "text"
      },
      "source": [
        "## More Practice with Joins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElKSaWR9et3t",
        "colab_type": "text"
      },
      "source": [
        "You can use the same select statement you built in the last exercise, however, let's add a twist and only return a few columns and use the other table in a `group_by()` clause."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhSBQEElewzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a statement to select the state, sum of 2008 population and census\n",
        "# division name: stmt\n",
        "stmt = select([\n",
        "    census.columns.state,\n",
        "    func.sum(census.columns.pop2008),\n",
        "    state_fact.columns.census_division_name\n",
        "])\n",
        "\n",
        "# Append select_from to join the census and state_fact tables by the census state and state_fact name columns\n",
        "stmt = stmt.select_from(\n",
        "    census.join(state_fact, census.columns.state == state_fact.columns.name)\n",
        ")\n",
        "\n",
        "# Append a group by for the state_fact name column\n",
        "stmt = stmt.group_by(state_fact.columns.name)\n",
        "\n",
        "# Execute the statement and get the results: results\n",
        "results = connection.execute(stmt).fetchall()\n",
        "\n",
        "# Loop over the the results object and print each record.\n",
        "for record in results:\n",
        "    print(record)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu4nuzGfe2BB",
        "colab_type": "text"
      },
      "source": [
        "## Using alias to handle same table joined queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH6E-mxfe4ra",
        "colab_type": "text"
      },
      "source": [
        "Often, you'll have tables that contain hierarchical data, such as employees and managers who are also employees. For this reason, you may wish to join a table to itself on different columns. The `.alias()` method, which creates a copy of a table, helps accomplish this task. Because it's the same table, you only need a where clause to specify the join condition.\n",
        "\n",
        "Here, you'll use the `.alias()` method to build a query to join the `employees` table against itself to determine to whom everyone reports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh7Gt_aOhPC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (since in the course material there is no explicit explanation of\n",
        "# creating 'employees' table, we have to create it first using sqlite\n",
        "# engine, Table module and .insert() method)\n",
        "\n",
        "# (import related modules)\n",
        "from sqlalchemy import Column, Integer, String, DATETIME, NUMERIC\n",
        "\n",
        "# (create sqlite engine and make a connection)\n",
        "engine_2 = create_engine('sqlite:///:memory:')\n",
        "conn = engine_2.connect()\n",
        "\n",
        "# (define the 'employees' table with predefined columns)\n",
        "employees = Table('employees', MetaData(bind=None), \n",
        "                  Column('id', Integer, primary_key=True, nullable=False), \n",
        "                  Column('name', String(20)), \n",
        "                  Column('job', String(20)), \n",
        "                  Column('mgr', Integer), \n",
        "                  Column('hiredate', DATETIME()), \n",
        "                  Column('sal', NUMERIC(precision=7, scale=2)), \n",
        "                  Column('comm', NUMERIC(precision=7, scale=2)), \n",
        "                  Column('dept', Integer))\n",
        "\n",
        "# (create the 'employees' table using the connected engine)\n",
        "employees.create(engine_2)\n",
        "\n",
        "# (insert all the rows as dictionaries with .insert() method)\n",
        "conn.execute(employees.insert(),[\n",
        "   {'name':'JOHNSON','job':'ADMIN', 'mgr':'6', 'sal':'18000.00', 'comm':None, 'dept':'4'},\n",
        "   {'name':'HARDING','job':'MANAGER', 'mgr':'9', 'sal':'52000.00', 'comm':'300.00', 'dept':'3'},\n",
        "   {'name':'TAFT','job':'SALES I', 'mgr':'2', 'sal':'25000.00', 'comm':'500.00', 'dept':'3'},\n",
        "   {'name':'HOOVER','job':'SALES I', 'mgr':'2', 'sal':'27000.00', 'comm':None, 'dept':'3'},\n",
        "   {'name':'LINCOLN','job':'TECH', 'mgr':'6', 'sal':'22500.00', 'comm':'1400.00', 'dept':'4'},\n",
        "   {'name':'GARFIELD','job':'MANAGER', 'mgr':'9', 'sal':'54000.00', 'comm':None, 'dept':'4'},\n",
        "   {'name':'POLK','job':'TECH', 'mgr':'6', 'sal':'25000.00', 'comm':None, 'dept':'4'},\n",
        "   {'name':'GRANT','job':'ENGINEER', 'mgr':'10', 'sal':'32000.00', 'comm':None, 'dept':'2'},\n",
        "   {'name':'JACKSON','job':'CEO', 'mgr':None, 'sal':'75000.00', 'comm':None, 'dept':'4'},\n",
        "   {'name':'FILLMORE','job':'MANAGER', 'mgr':'9', 'sal':'56000.00', 'comm':None, 'dept':'2'},\n",
        "   {'name':'ADAMS','job':'ENGINEER', 'mgr':'10', 'sal':'34000.00', 'comm':None, 'dept':'2'},\n",
        "   {'name':'WASHINGTON','job':'ADMIN', 'mgr':'6', 'sal':'18000.00', 'comm':None, 'dept':'4'},\n",
        "   {'name':'MONROE','job':'ENGINEER', 'mgr':'10', 'sal':'30000.00', 'comm':None, 'dept':'2'},\n",
        "   {'name':'ROOSEVELT','job':'CPA', 'mgr':'9', 'sal':'35000.00', 'comm':None, 'dept':'1'},\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvdvY8QLfBsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make an alias of the employees table: managers\n",
        "managers = employees.alias()\n",
        "\n",
        "# Build a query to select manager's and their employees names: stmt\n",
        "stmt = select(\n",
        "    [managers.columns.name.label('manager'),\n",
        "     employees.columns.name.label('employee')]\n",
        ")\n",
        "\n",
        "# Match managers id with employees mgr: stmt\n",
        "stmt = stmt.where(managers.columns.id == employees.columns.mgr)\n",
        "\n",
        "# Order the statement by the managers name: stmt\n",
        "stmt = stmt.order_by(managers.columns.name)\n",
        "\n",
        "# Execute statement: results\n",
        "results = conn.execute(stmt).fetchall()\n",
        "\n",
        "# Print records\n",
        "for record in results:\n",
        "    print(record)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXoBa8kRquWS",
        "colab_type": "text"
      },
      "source": [
        "## Leveraging Functions and Group_bys with Hierarchical Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSve1l_XqxaG",
        "colab_type": "text"
      },
      "source": [
        "It's also common to want to roll up data which is in a hierarchical table. Rolling up data requires making sure you're careful which alias you use to perform the group_bys and which table you use for the function.\n",
        "\n",
        "Here, your job is to get a count of employees for each manager."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WLwpw0oqzo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make an alias of the employees table: managers\n",
        "managers = employees.alias()\n",
        "\n",
        "# Build a query to select managers and counts of their employees: stmt\n",
        "stmt = select([managers.columns.name, func.count(employees.columns.id)])\n",
        "\n",
        "# Append a where clause that ensures the manager id and employee mgr are equal\n",
        "stmt = stmt.where(managers.columns.id == employees.columns.mgr)\n",
        "\n",
        "# Group by Managers Name\n",
        "stmt = stmt.group_by(managers.columns.name)\n",
        "\n",
        "# Execute statement: results\n",
        "results = conn.execute(stmt).fetchall()\n",
        "\n",
        "# print manager\n",
        "for record in results:\n",
        "    print(record)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdJjR2ZVrCwK",
        "colab_type": "text"
      },
      "source": [
        "## Working on Blocks of Records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TtzarrirDxO",
        "colab_type": "text"
      },
      "source": [
        "Fantastic work so far! As Jason discussed in the video, sometimes you may have the need to work on a large ResultProxy, and you may not have the memory to load all the results at once. To work around that issue, you can get blocks of rows from the ResultProxy by using the `.fetchmany()` method inside a loop. With `.fetchmany()`, give it an argument of the number of records you want. When you reach an empty list, there are no more rows left to fetch, and you have processed all the results of the query. Then you need to use the `.close()` method to close out the connection to the database.\n",
        "\n",
        "You'll now have the chance to practice this on a large ResultProxy called `results_proxy` that has been pre-loaded for you to work with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRkRPoi0rbWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (prepared the results_proxy)\n",
        "stmt = select([census])\n",
        "results_proxy = connection.execute(stmt)\n",
        "\n",
        "# (define 'more_results' as True)\n",
        "more_results = True\n",
        "\n",
        "# (define 'state_count' as an empty dictionary)\n",
        "state_count = dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5oXgQhsrMc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start a while loop checking for more results\n",
        "while more_results:\n",
        "    # Fetch the first 50 results from the ResultProxy: partial_results\n",
        "    partial_results = results_proxy.fetchmany(50)\n",
        "\n",
        "    # if empty list, set more_results to False\n",
        "    if partial_results == []:\n",
        "        more_results = False\n",
        "\n",
        "    # Loop over the fetched records and increment the count for the state\n",
        "    for row in partial_results:\n",
        "        if row.state in state_count:\n",
        "            state_count[row.state] += 1\n",
        "        else:\n",
        "            state_count[row.state] = 1\n",
        "\n",
        "# Close the ResultProxy, and thus the connection\n",
        "results_proxy.close()\n",
        "\n",
        "# Print the count by state\n",
        "print(state_count)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}